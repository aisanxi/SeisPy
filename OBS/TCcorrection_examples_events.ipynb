{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tilt and Compliance Corrections for OBS Data\n",
    "This notebook contains the functions used to conduct tilt and compliance corrections for OBS records. Examples using data directly downloaded from IRIS are also provided at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed packages.\n",
    "from collections import OrderedDict\n",
    "from utilities import sta_info_from_inv,plot_trace,segment_interpolate\n",
    "# from utilities import qml_to_event_list\n",
    "from TCcorrection_funcs import docorrection,gettransfer, maxcompfreq\n",
    "import sys\n",
    "import time\n",
    "import scipy\n",
    "import obspy\n",
    "import pyasdf\n",
    "import datetime\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "from IPython.display import clear_output\n",
    "from obspy.core.event import Catalog\n",
    "from obspy.geodetics.base import gps2dist_azimuth\n",
    "try:\n",
    "    from obspy.core.event import readEvents\n",
    "except Exception as e:\n",
    "    from obspy import read_events as readEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################### qml_to_event_list #####################################\n",
    "# modified from obspyDMT.utils.event_handler.py\n",
    "def qml_to_event_list(events_QML):\n",
    "    \"\"\"\n",
    "    convert QML to event list\n",
    "    :param events_QML:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    for i in range(len(events_QML)):\n",
    "        try:\n",
    "            event_time = events_QML.events[i].preferred_origin().time or \\\n",
    "                         events_QML.events[i].origins[0].time\n",
    "            event_time_month = '%02i' % int(event_time.month)\n",
    "            event_time_day = '%02i' % int(event_time.day)\n",
    "            event_time_hour = '%02i' % int(event_time.hour)\n",
    "            event_time_minute = '%02i' % int(event_time.minute)\n",
    "            event_time_second = '%02i' % int(event_time.second)\n",
    "\n",
    "            if not hasattr(events_QML.events[i], 'preferred_mag'):\n",
    "                events_QML.events[i].preferred_mag = \\\n",
    "                    events_QML.events[i].magnitudes[0].mag\n",
    "                events_QML.events[i].preferred_mag_type = \\\n",
    "                    events_QML.events[i].magnitudes[0].magnitude_type\n",
    "                events_QML.events[i].preferred_author = 'None'\n",
    "            else:\n",
    "                if not hasattr(events_QML.events[i], 'preferred_author'):\n",
    "                    if events_QML.events[i].preferred_magnitude().creation_info:\n",
    "                        events_QML.events[i].preferred_author = \\\n",
    "                            events_QML.events[i].preferred_magnitude().creation_info.author\n",
    "                    elif events_QML.events[i].magnitudes[0].creation_info:\n",
    "                        events_QML.events[i].preferred_author = \\\n",
    "                            events_QML.events[i].magnitudes[0].creation_info.author\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            continue\n",
    "        try:\n",
    "            if not events_QML.events[i].focal_mechanisms == []:\n",
    "                if events_QML.events[i].preferred_focal_mechanism()['moment_tensor']['tensor']:\n",
    "                    focal_mechanism = [\n",
    "                        events_QML.events[i].preferred_focal_mechanism()\n",
    "                        ['moment_tensor']['tensor']['m_rr'],\n",
    "                        events_QML.events[i].preferred_focal_mechanism()\n",
    "                        ['moment_tensor']['tensor']['m_tt'],\n",
    "                        events_QML.events[i].preferred_focal_mechanism()\n",
    "                        ['moment_tensor']['tensor']['m_pp'],\n",
    "                        events_QML.events[i].preferred_focal_mechanism()\n",
    "                        ['moment_tensor']['tensor']['m_rt'],\n",
    "                        events_QML.events[i].preferred_focal_mechanism()\n",
    "                        ['moment_tensor']['tensor']['m_rp'],\n",
    "                        events_QML.events[i].preferred_focal_mechanism()\n",
    "                        ['moment_tensor']['tensor']['m_tp']]\n",
    "                else:\n",
    "                    found_foc_mech = False\n",
    "                    for foc_mech_qml in events_QML.events[i].focal_mechanisms:\n",
    "                        if foc_mech_qml['moment_tensor']['tensor']:\n",
    "                            focal_mechanism = [\n",
    "                                foc_mech_qml['moment_tensor']['tensor']['m_rr'],\n",
    "                                foc_mech_qml['moment_tensor']['tensor']['m_tt'],\n",
    "                                foc_mech_qml['moment_tensor']['tensor']['m_pp'],\n",
    "                                foc_mech_qml['moment_tensor']['tensor']['m_rt'],\n",
    "                                foc_mech_qml['moment_tensor']['tensor']['m_rp'],\n",
    "                                foc_mech_qml['moment_tensor']['tensor']['m_tp']\n",
    "                            ]\n",
    "                            found_foc_mech = True\n",
    "                            break\n",
    "                    if not found_foc_mech:\n",
    "                        focal_mechanism = False\n",
    "            else:\n",
    "                focal_mechanism = False\n",
    "        except AttributeError:\n",
    "            print(\"[WARNING] focal_mechanism does not exist for \" \\\n",
    "                  \"event: %s -- set to False\" % (i+1))\n",
    "            focal_mechanism = False\n",
    "        except TypeError:\n",
    "            focal_mechanism = False\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            focal_mechanism = False\n",
    "\n",
    "        try:\n",
    "            if not events_QML.events[i].focal_mechanisms == []:\n",
    "                source_duration = [\n",
    "                    events_QML.events[i].preferred_focal_mechanism()\n",
    "                    ['moment_tensor']['source_time_function']['type'],\n",
    "                    events_QML.events[i].preferred_focal_mechanism()\n",
    "                    ['moment_tensor']['source_time_function']\n",
    "                    ['duration']]\n",
    "                if not source_duration[1]:\n",
    "                    source_duration = mag_duration(\n",
    "                        mag=events_QML.events[i].preferred_mag)\n",
    "            else:\n",
    "                source_duration = mag_duration(\n",
    "                    mag=events_QML.events[i].preferred_mag)\n",
    "        except AttributeError:\n",
    "            print(\"[WARNING] source duration does not exist for \" \\\n",
    "                  \"event: %s -- set to False\" % (i+1))\n",
    "            source_duration = False\n",
    "        except TypeError:\n",
    "            source_duration = False\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            source_duration = False\n",
    "\n",
    "        try:\n",
    "            events.append(OrderedDict(\n",
    "                [('number', i+1),\n",
    "                 ('latitude',\n",
    "                  events_QML.events[i].preferred_origin().latitude or\n",
    "                  events_QML.events[i].origins[0].latitude),\n",
    "                 ('longitude',\n",
    "                  events_QML.events[i].preferred_origin().longitude or\n",
    "                  events_QML.events[i].origins[0].longitude),\n",
    "                 ('depth',\n",
    "                  events_QML.events[i].preferred_origin().depth/1000. or\n",
    "                  events_QML.events[i].origins[0].depth/1000.),\n",
    "                 ('datetime', event_time),\n",
    "                 ('magnitude',\n",
    "                  events_QML.events[i].preferred_mag),\n",
    "                 ('magnitude_type',\n",
    "                  events_QML.events[i].preferred_mag_type),\n",
    "                 ('author',\n",
    "                  events_QML.events[i].preferred_author),\n",
    "                 ('event_id', str(event_time.year) +\n",
    "                  event_time_month + event_time_day + '_' +\n",
    "                  event_time_hour + event_time_minute +\n",
    "                  event_time_second + '.a'),\n",
    "                 ('origin_id', events_QML.events[i].preferred_origin_id or\n",
    "                  events_QML.events[i].origins[0].resource_id.resource_id),\n",
    "                 ('focal_mechanism', focal_mechanism),\n",
    "                 ('source_duration', source_duration),\n",
    "                 ('flynn_region', 'NAN'),\n",
    "                 ]))\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            continue\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_start= '2012-01-01'\n",
    "evt_end = '2012-01-31'\n",
    "evlon_min = -133\n",
    "evlon_max = -116\n",
    "evlat_min = 38\n",
    "evlat_max = 52\n",
    "evmag_min = 5.0\n",
    "evmag_max = 10.0\n",
    "evdep_min = 0\n",
    "evdep_max = 100\n",
    "\n",
    "cat=Catalog()\n",
    "cat = readEvents('http://www.ldeo.columbia.edu/~gcmt/projects/CMT/catalog/COMBO/combo.ndk')\n",
    "# cat=readEvents('./gcmtcombo.ndk')\n",
    "filt1 = 'time >= %s' % evt_start\n",
    "filt2 = 'time <= %s' % evt_end\n",
    "cat = cat.filter(filt1, filt2)\n",
    "\n",
    "filt1 = 'magnitude >= %s' % evmag_min\n",
    "filt2 = 'magnitude <= %s' % evmag_max\n",
    "cat = cat.filter(filt1, filt2)\n",
    "\n",
    "filt1 = 'depth >= %s' % (float(evdep_min)*1000.)\n",
    "filt2 = 'depth <= %s' % (float(evdep_max)*1000.)\n",
    "cat = cat.filter(filt1, filt2)\n",
    "\n",
    "if None not in [evlat_min, evlat_max, evlon_min, evlon_max]:\n",
    "    filt1 = 'latitude >= %s' % evlat_min\n",
    "    filt2 = 'latitude <= %s' % evlat_max\n",
    "    cat = cat.filter(filt1, filt2)\n",
    "\n",
    "    filt1 = 'longitude >= %s' % evlon_min\n",
    "    filt2 = 'longitude <= %s' % evlon_max\n",
    "    cat = cat.filter(filt1, filt2)\n",
    "\n",
    "#\n",
    "events=qml_to_event_list(cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev=events[0] #only work on the first event for now.\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get station list based on the event information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client    = Client('IRIS')\n",
    "# netall=\"7D\"\n",
    "stlamin,stlamax,stlomin,stlomax= 37.0,52.0,-133.0,-116.0\n",
    "Pchanlist=[\"HDH\",\"BDH\"] #pressure channels\n",
    "# starttime = obspy.UTCDateTime(\"2012_01_21_0_0_0\")       \n",
    "# endtime   = obspy.UTCDateTime(\"2012_01_22_0_0_0\")\n",
    "preset=200 #seconds before the origin time\n",
    "offset=3600 #seconds after the origin time\n",
    "starttime = ev['datetime'] - preset\n",
    "endtime = ev['datetime'] + offset\n",
    "\n",
    "pchanfound=0\n",
    "try:\n",
    "    sta_invP = client.get_stations(network='7D',station='*',channel='*DH',location='*', \\\n",
    "                    starttime=starttime,endtime=endtime,minlatitude=stlamin,maxlatitude=stlamax, \\\n",
    "                    minlongitude=stlomin, maxlongitude=stlomax,level='response')\n",
    "\n",
    "    pchanfound=1\n",
    "except Exception as e:\n",
    "    pchanfound == 0\n",
    "\n",
    "sta,netall,lon,lat,elv,location=sta_info_from_inv(sta_invP)\n",
    "print(sta,netall,lon,lat,elv,location)          \n",
    "stalist=sta#[\"G03A\",\"J35A\",\"J44A\",\"J65A\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from IRIS web service\n",
    "rmresp=True #remove instrument response\n",
    "rmrespoutput=\"DISP\"\n",
    "# parameters for butterworth filter\n",
    "samp_freq=20\n",
    "pfreqmin=0.005\n",
    "pfreqmax=samp_freq/2\n",
    "\n",
    "# prefilter information used when removing instrument responses\n",
    "f1 = 0.9*pfreqmin;f2=pfreqmin\n",
    "if 1.1*pfreqmax > 0.45*samp_freq:\n",
    "    f3 = 0.4*samp_freq\n",
    "    f4 = 0.45*samp_freq\n",
    "else:\n",
    "    f3 = pfreqmax\n",
    "    f4= 1.1*pfreqmax\n",
    "pre_filt  = [f1,f2,f3,f4]\n",
    "\n",
    "# get relationship between water depth and maximum compliance frequency.\n",
    "d=np.arange(1,5051,50) #water depth\n",
    "f=maxcompfreq(d,iplot=True)\n",
    "trmaster=[]\n",
    "trlabelsmaster=[]\n",
    "distall=[]\n",
    "for i in range(len(stalist)):\n",
    "    ista=stalist[i]\n",
    "    net=netall[i]\n",
    "    clear_output(wait=True)\n",
    "    trall=[] \n",
    "    stinv=[]\n",
    "    trlabels=[]\n",
    "    \"\"\"\n",
    "    array to save all four set of traces: 0-pressure, 1-vertical, 2-prediction of vertical from pressure,\n",
    "    3-corrected vertical\n",
    "    \"\"\"\n",
    "    \n",
    "    #download pressure data first\n",
    "    pchanfound=0\n",
    "    for chan in Pchanlist:\n",
    "        try:\n",
    "            sta_invP = client.get_stations(network=net,station=ista,channel=chan,location='*', \\\n",
    "                            starttime=starttime,endtime=endtime,minlatitude=stlamin,maxlatitude=stlamax, \\\n",
    "                            minlongitude=stlomin, maxlongitude=stlomax,level='response')\n",
    "            print()\n",
    "            pchan=chan\n",
    "            pchanfound=1\n",
    "            break\n",
    "        except Exception as e:\n",
    "            pchanfound == 0\n",
    "            \n",
    "    if pchanfound == 0 and chan == Pchanlist[-1]:\n",
    "        print(\"Pressure channels not found for \"+net+\".\"+ista)\n",
    "        continue\n",
    "    sta,net,lon,lat,elv,location=sta_info_from_inv(sta_invP)\n",
    "    dist=gps2dist_azimuth(lat[0],lon[0],ev['latitude'],ev['longitude'])\n",
    "    sta=sta[0]\n",
    "    net=net[0]\n",
    "    elv=elv[0]\n",
    "    stinv.append(sta_invP)\n",
    "    trlabels.append(net+\".\"+ista+\".\"+pchan+\":\"+str(np.abs(elv))+\"m:pressure\")\n",
    "    print(\"pressure channel \"+pchan)\n",
    "    try:\n",
    "        tr=client.get_waveforms(network=net,station=ista,\\\n",
    "                        channel=pchan,location=\"*\",starttime=starttime,endtime=endtime)\n",
    "        tr.detrend(\"spline\", order=3, dspline=500)\n",
    "        trall.append(tr[0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(trlabels[0])\n",
    "        continue\n",
    "\n",
    "    #download vertical data now\n",
    "    zchan=pchan[0]+\"HZ\"\n",
    "    try:\n",
    "        sta_invZ = client.get_stations(network=net,station=ista,channel=zchan,location='*', \\\n",
    "                        starttime=starttime,endtime=endtime,minlatitude=stlamin,maxlatitude=stlamax, \\\n",
    "                        minlongitude=stlomin, maxlongitude=stlomax,level='response')\n",
    "\n",
    "        stinv.append(sta_invZ)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    print(\"vertical channel \"+zchan)\n",
    "    trlabels.append(net+\".\"+ista+\".\"+zchan+\":\"+str(np.abs(elv))+\"m:vertical\")\n",
    "    try:\n",
    "        tr=client.get_waveforms(network=net,station=ista,\\\n",
    "                        channel=zchan,location=\"*\",starttime=starttime,endtime=endtime)\n",
    "        tr.detrend(\"spline\", order=3, dspline=500)\n",
    "        trall.append(tr[0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(trlabels[1])\n",
    "        continue\n",
    "\n",
    "    sps=int(trall[0].stats.sampling_rate) #assume pressure and vertical channels have the same sampling rat\n",
    "    # make downsampling if needed\n",
    "    if sps > samp_freq:\n",
    "        # downsampling here\n",
    "        print(\"resampling from \"+str(sps)+\" to \"+str(samp_freq))\n",
    "        for it in range(len(trall)):\n",
    "            trall[it].interpolate(samp_freq,method='weighted_average_slopes')\n",
    "            delta = trall[it].stats.delta\n",
    "\n",
    "            # when starttimes are between sampling points\n",
    "            fric = trall[it].stats.starttime.microsecond%(delta*1E6)\n",
    "            if fric>1E-4:\n",
    "                trall[it].data = segment_interpolate(np.float32(trall[it].data),float(fric/(delta*1E6)))\n",
    "                #--reset the time to remove the discrepancy---\n",
    "                trall[it].stats.starttime-=(fric*1E-6)\n",
    "\n",
    "    #remove response from the two downloaded channels\n",
    "    if rmresp:\n",
    "        for it in range(len(trall)):\n",
    "            if it == 0:continue #skip pressure channel\n",
    "            if not stinv[it][0][0][0].response:\n",
    "                raise ValueError('no response found in the inventory! abort!')\n",
    "            else:\n",
    "                try:\n",
    "                    print('removing response for %s using inv'%trall[it])\n",
    "                    trall[it].attach_response(stinv[it])\n",
    "                    trall[it].remove_response(output=rmrespoutput,pre_filt=pre_filt,water_level=60)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    trall[it] = []\n",
    "           \n",
    "    #start compliance correction\n",
    "    #get the transfer function\n",
    "    freqmin=pfreqmin\n",
    "    freqmax=np.around(maxcompfreq(np.abs(elv)),decimals=3)\n",
    "#     freqmin=0.01\n",
    "#     freqmax=0.025\n",
    "    delta=1.0/samp_freq\n",
    "    print(\"getting transfer function ...\")\n",
    "#     trall[0].data=1000*trall[0].data #change from kpa to pa\n",
    "    ff,coh,adm,phs,adm_err,phs_err = gettransfer(trall[0].data,trall[1].data,\\\n",
    "                                                 delta,iplot=False,winlen=250,\\\n",
    "                                                figname=net+\".\"+ista+\".\"+pchan+\"-\"+zchan+\"_debug_transfer.png\")\n",
    "    if np.isnan(np.sum(adm)):\n",
    "        print(\"getting transfer function found nan in adm. skip to the next station.\")\n",
    "        continue\n",
    "        \n",
    "    # do correction now.\n",
    "    print(\"doing correction ...\")\n",
    "    trZ_pred,trZ_left = docorrection(trall[0],trall[1],adm,adm_err,phs,phs_err,\\\n",
    "                                     freqmin,freqmax,ff,iplot=0)\n",
    "\n",
    "    trall.append(trZ_pred)\n",
    "    trlabels.append(net+\".\"+ista+\".\"+zchan+\":\"+str(np.abs(elv))+\"m:prediction\")\n",
    "    trall.append(trZ_left)\n",
    "    trlabels.append(net+\".\"+ista+\".\"+zchan+\":\"+str(np.abs(elv))+\"m:compliance corrected\")\n",
    "\n",
    "    trmaster.append(trall)\n",
    "    trlabelsmaster.append(trlabels)\n",
    "    distall.append(dist)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "print(\"plotting ...\")\n",
    "pfreqmin=0.02\n",
    "pfreqmax=0.1\n",
    "xlimit=[0, 400]\n",
    "ylimit=[300, 800]\n",
    "scale=15\n",
    "figsize=[10,8]\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(len(trmaster)):\n",
    "    tc=trmaster[i][0].copy()\n",
    "    tt=tc.times();\n",
    "    if len(xlimit)>0:\n",
    "        imin = np.searchsorted(tt,xlimit[0],side=\"left\")\n",
    "        imax = np.searchsorted(tt,xlimit[1],side=\"left\")\n",
    "    else:\n",
    "        imin=0\n",
    "        imax=len(tc.data)-1\n",
    "    \n",
    "    tc.filter('bandpass',freqmin=pfreqmin,freqmax=pfreqmax)\n",
    "    dtemp=tc.data/np.max(np.abs(tc.data[imin:imax]))\n",
    "    plt.plot(tt-preset,distall[i][0]/1000 + scale*dtemp,'k')\n",
    "    plt.xlim(xlimit)\n",
    "    plt.ylim(ylimit)\n",
    "    plt.title('Pressure')\n",
    "# plt.close()\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(len(trmaster)):\n",
    "    tc=trmaster[i][1].copy()\n",
    "    tt=tc.times();\n",
    "    if len(xlimit)>0:\n",
    "        imin = np.searchsorted(tt,xlimit[0],side=\"left\")\n",
    "        imax = np.searchsorted(tt,xlimit[1],side=\"left\")\n",
    "    else:\n",
    "        imin=0\n",
    "        imax=len(tc.data)-1\n",
    "    tc.filter('bandpass',freqmin=pfreqmin,freqmax=pfreqmax)\n",
    "    dtemp=tc.data/np.max(np.abs(tc.data[imin:imax]))\n",
    "    plt.plot(tt-preset,distall[i][0]/1000 + scale*dtemp,'b')\n",
    "    plt.xlim(xlimit)\n",
    "    plt.ylim(ylimit)\n",
    "    plt.title('Vertical')\n",
    "# plt.close()    \n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(len(trmaster)):\n",
    "    tc=trmaster[i][2].copy()\n",
    "    tt=tc.times();\n",
    "    if len(xlimit)>0:\n",
    "        imin = np.searchsorted(tt,xlimit[0],side=\"left\")\n",
    "        imax = np.searchsorted(tt,xlimit[1],side=\"left\")\n",
    "    else:\n",
    "        imin=0\n",
    "        imax=len(tc.data)-1\n",
    "    tc.filter('bandpass',freqmin=pfreqmin,freqmax=pfreqmax)\n",
    "    dtemp=tc.data/np.max(np.abs(tc.data[imin:imax]))\n",
    "    plt.plot(tt-preset,distall[i][0]/1000 + scale*dtemp,'c')\n",
    "    plt.xlim(xlimit)\n",
    "    plt.ylim(ylimit)\n",
    "    plt.title('Prediction of vertical')\n",
    "# plt.close()\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(len(trmaster)):\n",
    "    tc=trmaster[i][3].copy()\n",
    "    tt=tc.times();\n",
    "    if len(xlimit)>0:\n",
    "        imin = np.searchsorted(tt,xlimit[0],side=\"left\")\n",
    "        imax = np.searchsorted(tt,xlimit[1],side=\"left\")\n",
    "    else:\n",
    "        imin=0\n",
    "        imax=len(tc.data)-1\n",
    "    tc.filter('bandpass',freqmin=pfreqmin,freqmax=pfreqmax)\n",
    "    dtemp=tc.data/np.max(np.abs(tc.data[imin:imax]))\n",
    "    plt.plot(tt-preset,distall[i][0]/1000 + scale*dtemp,'r')\n",
    "    plt.xlim(xlimit)\n",
    "    plt.ylim(ylimit)\n",
    "    plt.title('Vertical after correction')\n",
    "# plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
